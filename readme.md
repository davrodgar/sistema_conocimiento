# Sistema de Conocimiento para Documentos Empresariales

Este proyecto forma parte del Trabajo Fin de MÃ¡ster (TFM)  
del MÃ¡ster de IngenierÃ­a del Software de la Universidad de Sevilla.  
Su objetivo es desarrollar un sistema modular que procese documentos de texto en diferentes formatos, extraiga conocimiento relevante, lo almacene de forma estructurada y permita su consulta en lenguaje natural de manera local, sin dependencias externas.

---

## Estructura del sistema

1. **Ingesta de Documentos**  
   Detecta archivos nuevos en la carpeta `data/input/`, extrae su contenido mediante herramientas especializadas (Apache Tika, pdfplumber, python-docx, etc.) y registra todo en una base de datos SQLite.

2. **Procesamiento del Conocimiento**  
   Limpia, segmenta y vectoriza el contenido textual en fragmentos semÃ¡nticos, utilizando el modelo `MiniLM-L12-v2` para generar embeddings.

3. **Almacenamiento**  
   Utiliza SQLite para registrar los documentos, fragmentos, vectores y consultas, garantizando trazabilidad completa.

4. **Consulta en Lenguaje Natural**  
   Implementa un flujo de RAG (Retrieval-Augmented Generation) que permite realizar preguntas en lenguaje natural y obtener respuestas contextualizadas, usando el modelo `Mistral 7B` ejecutado localmente mediante Ollama.

5. **EvaluaciÃ³n y ValidaciÃ³n**  
   Incluye scripts para validar automÃ¡ticamente la calidad del contenido extraÃ­do, la segmentaciÃ³n y la recuperaciÃ³n semÃ¡ntica.

---

## ðŸ›  Requisitos

- Python 3.9 o superior
- Java (para ejecutar Apache Tika Server)
- Apache Tika server (`tika-server-standard.jar`) en `src/tools/`
- Ollama instalado localmente (`ollama run mistral`)
- Microsoft Word (solo necesario si se desea extraer contenido desde archivos `.doc`)
- Virtualenv (opcional pero recomendado)

---

## â–¶ï¸ InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/davrodgar/sistema_conocimiento.git
cd sistema_conocimiento

# Crear y activar el entorno virtual
python -m venv venv_TFM2025
# En Windows
venv_TFM2025\Scripts\activate
# En macOS/Linux
source venv_TFM2025/bin/activate

# Instalar las dependencias
pip install --upgrade pip
pip install -r requirements.txt
```

---

## ðŸš€ Uso rÃ¡pido

1. **Preparar los documentos**  
   Coloca los archivos a procesar en la carpeta `data/input/`.

2. **Ejecutar la ingesta y procesamiento**  
   Lanza los scripts principales desde la carpeta `src/` para extraer, segmentar y vectorizar los documentos.

   ```bash
   python src/ingesta_documentos.py
   python src/procesamiento_conocimiento.py
   ```

3. **Realizar consultas en lenguaje natural**  
   Ejecuta el script de recuperaciÃ³n semÃ¡ntica:

   ```bash
   python src/evaluacion_recuperacionsemantica.py
   ```

4. **Evaluar resultados**  
   Usa los scripts de evaluaciÃ³n para validar la segmentaciÃ³n y la recuperaciÃ³n:

   ```bash
   python src/evaluacion_segmentacion.py
   ```

---

## ðŸ“‚ Estructura de carpetas

```
sistema_conocimiento/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/           # Documentos originales
â”‚   â”œâ”€â”€ output/          # Resultados y fragmentos procesados
â”‚   â””â”€â”€ embeddings/      # Vectores generados
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingesta_documentos.py
â”‚   â”œâ”€â”€ procesamiento_conocimiento.py
â”‚   â”œâ”€â”€ evaluacion_segmentacion.py
â”‚   â”œâ”€â”€ evaluacion_recuperacionsemantica.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ readme.md
```

---

## ðŸ“ Notas

- El sistema estÃ¡ pensado para ejecutarse completamente en local, sin enviar datos a servicios externos.
- Se recomienda mantener actualizado el archivo `requirements.txt` usando `pip freeze > requirements.txt` tras instalar o actualizar paquetes.
- Para dudas o mejoras, abre un issue en el repositorio.

---
