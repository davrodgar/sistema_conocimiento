{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arodri\\Proyectos\\TFM_2025\\TFM2025\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Respuesta generada:\n",
      "Con base en los documentos analizados, la respuesta es:\n",
      "\n",
      "Efficiency and Feasibility: Best Use of Resources\n",
      "With the Burkina Faso HRP being severely underfunded, it is unclear whether this anticipatory\n",
      "action pilot diverts funding away from more urgent needs identified by the Food Security Cluster.\n",
      "‚óè Recommendation: Discuss the potential impacts that $15 million could have on the\n",
      "region or globally and compare to the impacts of the no-regrets approach.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Cargar el modelo de embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Par√°metros de filtrado\n",
    "UMBRAL_BASE = 0.60  \n",
    "UMBRAL_MAXIMO = 0.45  \n",
    "MIN_DOCUMENTOS_RELEVANTES = 1  \n",
    "\n",
    "def cargar_embeddings_desde_archivo(ruta_archivo):\n",
    "    \"\"\"Carga los embeddings desde un archivo JSON.\"\"\"\n",
    "    with open(ruta_archivo, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data[\"archivo\"], data[\"secciones\"]\n",
    "\n",
    "def calcular_similitud(embedding1, embedding2):\n",
    "    \"\"\"Calcula la similitud mediante la distancia del coseno.\"\"\"\n",
    "    return cosine(embedding1, embedding2)\n",
    "\n",
    "def buscar_documentos_similares(texto, carpeta_embeddings):\n",
    "    \"\"\"\n",
    "    Busca documentos en una carpeta que sean m√°s similares al texto de entrada.\n",
    "    Retorna una lista de tuplas con el nombre del archivo, la menor distancia y el p√°rrafo m√°s similar.\n",
    "    \"\"\"\n",
    "    embedding_texto = embedding_model.encode(texto)\n",
    "    resultados = {}\n",
    "\n",
    "    for archivo in os.listdir(carpeta_embeddings):\n",
    "        if archivo.endswith(\"_embeddings.json\"):\n",
    "            ruta_archivo = os.path.join(carpeta_embeddings, archivo)\n",
    "            nombre_archivo, secciones = cargar_embeddings_desde_archivo(ruta_archivo)\n",
    "\n",
    "            menor_distancia = float(\"inf\")\n",
    "            parrafo_mas_similar = \"\"\n",
    "\n",
    "            for seccion in secciones:\n",
    "                embedding_parrafo = np.array(seccion[\"embedding\"])\n",
    "                distancia = calcular_similitud(embedding_texto, embedding_parrafo)\n",
    "\n",
    "                if distancia < menor_distancia:\n",
    "                    menor_distancia = distancia\n",
    "                    parrafo_mas_similar = seccion[\"texto\"]\n",
    "\n",
    "            resultados[nombre_archivo] = (menor_distancia, parrafo_mas_similar)\n",
    "\n",
    "    resultados_ordenados = sorted(resultados.items(), key=lambda x: x[1][0])\n",
    "\n",
    "    umbral_actual = UMBRAL_BASE\n",
    "    documentos_relevantes = [(archivo, distancia, parrafo) for archivo, (distancia, parrafo) in resultados_ordenados if distancia <= umbral_actual]\n",
    "\n",
    "    if len(documentos_relevantes) < MIN_DOCUMENTOS_RELEVANTES:\n",
    "        umbral_actual = UMBRAL_MAXIMO\n",
    "        documentos_relevantes = [(archivo, distancia, parrafo) for archivo, (distancia, parrafo) in resultados_ordenados if distancia <= umbral_actual]\n",
    "\n",
    "    if len(documentos_relevantes) < MIN_DOCUMENTOS_RELEVANTES:\n",
    "        return []\n",
    "\n",
    "    return documentos_relevantes\n",
    "\n",
    "def construir_respuesta(texto_pregunta, carpeta_embeddings):\n",
    "    \"\"\"\n",
    "    Construye una respuesta en lenguaje natural combinando los p√°rrafos m√°s similares.\n",
    "    \"\"\"\n",
    "    documentos_relevantes = buscar_documentos_similares(texto_pregunta, carpeta_embeddings)\n",
    "\n",
    "    if not documentos_relevantes:\n",
    "        return \"No se encontr√≥ una respuesta clara en los documentos.\"\n",
    "\n",
    "    respuesta = \"Con base en los documentos analizados, la respuesta es:\\n\\n\"\n",
    "\n",
    "    # Unir los mejores p√°rrafos asegurando coherencia\n",
    "    for _, _, parrafo in documentos_relevantes[:3]:  # Tomar hasta 3 p√°rrafos relevantes\n",
    "        respuesta += f\"{parrafo}\\n\\n\"\n",
    "\n",
    "    return respuesta.strip()\n",
    "\n",
    "# Ejemplo de uso\n",
    "carpeta_embeddings = \"data\"\n",
    "texto_pregunta = \"All the information about Burkina?\"\n",
    "\n",
    "respuesta = construir_respuesta(texto_pregunta, carpeta_embeddings)\n",
    "\n",
    "# Mostrar la respuesta generada\n",
    "print(\"\\nüîπ Respuesta generada:\")\n",
    "print(respuesta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
