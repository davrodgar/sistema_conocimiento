import os
import re
import json
import spacy

# Directorios
PROCESSED_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../data/processed"))
SEGMENTED_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../data/segmented"))

# Crear la carpeta de salida si no existe
if not os.path.exists(SEGMENTED_DIR):
    os.makedirs(SEGMENTED_DIR)

# Cargar modelo NER
nlp = spacy.load("es_core_news_sm")

def detectar_titulos(parrafo):
    """
    Detecta t√≠tulos dentro de un p√°rrafo.
    Un t√≠tulo es una l√≠nea que cumple ciertos criterios, como:
    - Estar en may√∫sculas.
    - Terminar con dos puntos (:).
    - Tener un formato de lista (por ejemplo, 1., a)).
    """
    lineas = parrafo.split("\n")
    titulos = [linea.strip() for linea in lineas if linea.isupper() or linea.strip().endswith(":") or re.match(r"^\d+[\.\)]", linea.strip())]
    return titulos

def extraer_entidades(parrafo):
    """
    Extrae entidades clave (NER) usando spaCy.
    """
    doc = nlp(parrafo)
    entidades = [
        {"texto": ent.text, "tipo": ent.label_}
        for ent in doc.ents
        if ent.label_ in ["PER", "ORG", "LOC", "MISC", "DATE"]  # Filtrar solo entidades √∫tiles
    ]
    return entidades

def segmentar_en_parrafos(texto):
    """
    Separa el texto en p√°rrafos usando:
    - Dobles saltos de l√≠nea
    - Punto seguido de salto de l√≠nea y una may√∫scula (inicio de un nuevo p√°rrafo)
    """
    # Normalizar saltos de l√≠nea
    texto = re.sub(r'\n+', '\n', texto)  # Reemplazar m√∫ltiples saltos de l√≠nea por uno solo

    # Separar por dobles saltos de l√≠nea o punto seguido de un salto de l√≠nea y may√∫scula
    parrafos = re.split(r"\n\s*\n|(?<=\.)\n(?=[A-Z])", texto)

    # Filtrar fragmentos muy cortos
    parrafos = [p.strip() for p in parrafos if len(p.strip()) > 30]

    return parrafos

def procesar_archivos_json():
    """
    Procesa todos los archivos JSON en la carpeta PROCESSED_DIR,
    extrae el contenido de "X-TIKA:content", lo segmenta en p√°rrafos,
    y guarda los resultados en SEGMENTED_DIR.
    """
    for archivo in os.listdir(PROCESSED_DIR):
        if archivo.endswith(".json"):
            ruta_archivo = os.path.join(PROCESSED_DIR, archivo)
            print(f"üìÇ Procesando archivo: {archivo}")

            # Leer el contenido del archivo JSON
            with open(ruta_archivo, "r", encoding="utf-8") as f:
                contenido = json.load(f)

            # Extraer el texto del atributo "X-TIKA:content"
            texto = contenido.get("X-TIKA:content", "")
            if not texto.strip():
                print(f"‚ö†Ô∏è El archivo {archivo} no contiene texto en 'X-TIKA:content'.")
                continue

            # Segmentar el texto en p√°rrafos
            parrafos = segmentar_en_parrafos(texto)
            print(f"üîπ Se detectaron {len(parrafos)} p√°rrafos en el archivo {archivo}")

            # Procesar cada p√°rrafo para detectar t√≠tulos y entidades NER
            resultado = {
                "archivo_origen": archivo,
                "parrafos": []
            }

            for idx, parrafo in enumerate(parrafos, start=1):
                # titulos = detectar_titulos(parrafo)  # L√≠nea comentada
                # entidades = extraer_entidades(parrafo)  # L√≠nea comentada

                # Calcular la longitud del p√°rrafo
                longitud_parrafo = len(parrafo)

                # Traza: Mostrar informaci√≥n del p√°rrafo
                print(f"  - P√°rrafo {idx}: {parrafo[:20]}... (Longitud: {longitud_parrafo})")  # Mostrar los primeros 20 caracteres del p√°rrafo y su longitud
                # print(f"  - P√°rrafo {idx}: {len(titulos)} t√≠tulos detectados, {len(entidades)} entidades detectadas.")  # L√≠nea comentada

                resultado["parrafos"].append({
                    "id_parrafo": idx,
                    "texto": parrafo,
                    "longitud": longitud_parrafo,  # Agregar la longitud del p√°rrafo al JSON
                    # "titulos": titulos,  # L√≠nea comentada
                    # "entidades": entidades  # L√≠nea comentada
                })

            # Guardar el resultado en un archivo JSON
            archivo_segmentado = os.path.join(SEGMENTED_DIR, archivo.replace(".json", "_segmented.json"))
            with open(archivo_segmentado, "w", encoding="utf-8") as f:
                json.dump(resultado, f, ensure_ascii=False, indent=4)

            print(f"‚úÖ Archivo segmentado guardado en: {archivo_segmentado}")

if __name__ == "__main__":
    procesar_archivos_json()